# -*- coding: utf-8 -*-
"""
YOLO (Standard / YOLO‚ÄëWorld) Object Detection + Tracking ‚Äî Streamlit App
======================================================================
This version is based on v2, implementing two key user-requested changes:
1.  **Limited Frame Processing**: A `MAX_PROCESSING_FPS` constant has been
    introduced. The video processing loop now skips frames to ensure that
    no more than this number of frames per second of video are analyzed,
    significantly speeding up processing for high-FPS videos.
2.  **Two-Step Download Process**: The download functionality is now separated
    into two user actions. A "Prepare Download" button first triggers the
    on-demand frame extraction, annotation, and zipping process. Only after
    this is complete does the "Download Results (ZIP)" button become active,
    improving UX and clarifying when the computationally expensive work happens.

TO INCREASE UPLOAD LIMIT:
-------------------------
To increase the file upload limit (e.g., to 2GB), run Streamlit from your
terminal with the following command:
streamlit run your_script_name.py --server.maxUploadSize 2048
"""

# -----------------------------------------------------------------------------
#  Workaround for Streamlit/PyTorch watcher issue with torch.classes
# -----------------------------------------------------------------------------
import torch
if hasattr(torch, 'classes') and hasattr(torch.classes, '__path__'):
    torch.classes.__path__ = []  # Must be at the top

# -----------------------------------------------------------------------------
#  Standard Libraries
# -----------------------------------------------------------------------------
import cv2
import tempfile
import os
import time
import logging
from collections import defaultdict
import shutil
import datetime
import math

# -----------------------------------------------------------------------------
#  Third-Party Libraries
# -----------------------------------------------------------------------------
import streamlit as st
from ultralytics import YOLO
import numpy as np

# -----------------------------------------------------------------------------
#  Logging Configuration
# -----------------------------------------------------------------------------
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# -----------------------------------------------------------------------------
#  Model Parameters
# -----------------------------------------------------------------------------
MODEL_TYPES = ["Standard YOLO", "YOLO-World"]

STANDARD_MODEL_CONFIG = {
    "model_path": "yolov8n.pt",
    "target_classes_ids": [0, 1, 2, 3, 5, 7],
    "target_classes_names": {0: "person", 1: "bicycle", 2: "car", 3: "motorcycle", 5: "bus", 7: "truck"},
    "confidence_threshold": 0.3,
    "display_name": "YOLOv8n (People & Vehicles)"
}

WORLD_MODEL_CONFIG = {
    "model_path": "yolov8s-worldv2.pt",
    "default_prompt": "person, car, bicycle, traffic light, backpack",
    "confidence_threshold": 0.1,
    "display_name": "YOLOv8s-World v2"
}

# -----------------------------------------------------------------------------
#  Processing & Drawing Parameters
# -----------------------------------------------------------------------------
MAX_PROCESSING_FPS = 3.0       # Limit processing to this many frames per second
TRACKER_CONFIG = "bytetrack.yaml"
BOX_COLOR = (0, 255, 0)      # BGR
BOX_THICKNESS = 2
TEXT_COLOR_ON_BG = (0, 0, 0)  # Black text
TEXT_BG_COLOR = (0, 255, 0)   # Green background
TEXT_FONT_SCALE = 0.5
TEXT_THICKNESS = 1
TEXT_FONT = cv2.FONT_HERSHEY_SIMPLEX

# --- Output Folder Settings ---
BASE_OUTPUT_DIR = "yolo_detection_results"

# -----------------------------------------------------------------------------
#  Helper ‚Äî Timestamp Formatter
# -----------------------------------------------------------------------------
def format_timestamp(seconds, for_filename=False):
    """Converts seconds to HH:MM:SS or HH_MM_SS string format."""
    if seconds is None or seconds < 0:
        return "00_00_00" if for_filename else "00:00:00"
    td = datetime.timedelta(seconds=seconds)
    hours, remainder = divmod(td.seconds, 3600)
    minutes, seconds_val = divmod(remainder, 60)
    if for_filename:
        return f"{hours:02d}_{minutes:02d}_{seconds_val:02d}"
    else:
        return f"{hours:02d}:{minutes:02d}:{seconds_val:02d}"

# -----------------------------------------------------------------------------
#  Helper ‚Äî Load Model
# -----------------------------------------------------------------------------
@st.cache_resource
def load_model_unified(model_path):
    try:
        logging.info(f"Loading model: {model_path}")
        model = YOLO(model_path)
        logging.info(f"Model {model_path} loaded successfully.")
        return model
    except Exception as e:
        st.error(f"Failed to load model '{model_path}': {e}")
        logging.exception(f"Error loading model '{model_path}': {e}")
        return None

# -----------------------------------------------------------------------------
#  Helper ‚Äî Draw Bounding Box
# -----------------------------------------------------------------------------
def draw_bounding_box_unified(frame, box, track_id, class_name, conf):
    """Draws a single bounding box on a copy of the frame."""
    img = frame.copy()
    x1, y1, x2, y2 = map(int, box)
    label = f"ID:{track_id} {class_name} {conf:.2f}"
    cv2.rectangle(img, (x1, y1), (x2, y2), BOX_COLOR, BOX_THICKNESS)
    (w, h), _ = cv2.getTextSize(label, TEXT_FONT, TEXT_FONT_SCALE, TEXT_THICKNESS)
    label_y = y1 - 10 if y1 - 10 > h else y1 + h + 10
    label_x1 = max(0, x1)
    label_x2 = label_x1 + w
    cv2.rectangle(img, (label_x1, label_y - h - 5), (label_x2, label_y), TEXT_BG_COLOR, -1)
    cv2.putText(img, label, (label_x1, label_y - 3), TEXT_FONT, TEXT_FONT_SCALE, TEXT_COLOR_ON_BG, TEXT_THICKNESS, cv2.LINE_AA)
    return img

# -----------------------------------------------------------------------------
#  Helper ‚Äî On-Demand Frame Extraction from Video
# -----------------------------------------------------------------------------
def extract_frames_by_indices(video_path, frame_indices):
    """
    Efficiently extracts specific frames from a video file based on their indices.
    Args:
        video_path (str): The path to the video file.
        frame_indices (list or set): A collection of frame indices to extract.
    Returns:
        dict: A dictionary mapping each frame index to its corresponding BGR frame.
    """
    if not frame_indices:
        return {}

    extracted_frames = {}
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        logging.error(f"Could not open video file for frame extraction: {video_path}")
        return {}

    # Sort indices to read frames sequentially for better performance
    sorted_indices = sorted(list(set(frame_indices)))

    for index in sorted_indices:
        cap.set(cv2.CAP_PROP_POS_FRAMES, index)
        ret, frame = cap.read()
        if ret:
            extracted_frames[index] = frame
        else:
            logging.warning(f"Could not read frame at index {index} from {video_path}. It may be out of bounds.")

    cap.release()
    return extracted_frames

# -----------------------------------------------------------------------------
#  Helper ‚Äî Process Video (Detect + Track)
# -----------------------------------------------------------------------------
def process_video_unified(video_path, model, is_world_model, current_model_settings,
                          yolo_world_custom_classes, confidence_thresh, progress_bar_element):
    tracked_object_info = defaultdict(list)
    representative_frames = {}
    max_box_areas = defaultdict(float)

    if not hasattr(progress_bar_element, "progress"):
        class DummyProgressBar:
            def progress(self, *_args, **_kw): pass
            def empty(self): pass
        progress_bar_element = DummyProgressBar()
        logging.warning("process_video_unified: No valid progress_bar_element passed, using dummy.")

    try:
        active_classes_for_tracking_param = None
        class_name_source_map_or_list = {}

        if is_world_model:
            if not yolo_world_custom_classes:
                st.warning("YOLO-World model requires at least one class to detect.")
                logging.warning("YOLO-World: Processing attempted without specified classes.")
                return {}, {}
            model.set_classes(yolo_world_custom_classes)
            class_name_source_map_or_list = yolo_world_custom_classes
            active_classes_for_tracking_param = list(range(len(yolo_world_custom_classes)))
            logging.info(f"YOLO-World: Set classes: {', '.join(yolo_world_custom_classes)}, Tracking indices: {active_classes_for_tracking_param}")
        else:
            active_classes_for_tracking_param = current_model_settings["target_classes_ids"]
            class_name_source_map_or_list = current_model_settings["target_classes_names"]
            logging.info(f"Standard YOLO: Using fixed class IDs: {active_classes_for_tracking_param}")

        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            st.error("Cannot open video file.")
            logging.error(f"Cannot open video file: {video_path}")
            return {}, {}

        video_fps = cap.get(cv2.CAP_PROP_FPS)
        if video_fps <= 0:
            logging.warning(f"Video FPS read as zero or negative ({video_fps}). Timestamps may be inaccurate. Defaulting to 30 FPS.")
            video_fps = 30.0

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        pb_instance = progress_bar_element.progress(0, text="Processing video‚Ä¶")
        start_time = time.time()
        frame_idx = 0
        last_processed_time = -1.0
        time_increment = 1.0 / MAX_PROCESSING_FPS

        while cap.isOpened():
            ok, frame = cap.read()
            if not ok: break

            current_timestamp_seconds = frame_idx / video_fps

            # Frame skipping logic
            if current_timestamp_seconds >= last_processed_time + time_increment:
                last_processed_time = current_timestamp_seconds

                # --- Main processing logic for the frame ---
                track_params = dict(
                    source=frame, tracker=TRACKER_CONFIG, conf=confidence_thresh,
                    persist=True, verbose=False, classes=active_classes_for_tracking_param
                )
                results = model.track(**track_params)

                if results and results[0].boxes is not None and results[0].boxes.id is not None:
                    boxes_coords = results[0].boxes.xyxy.cpu().numpy()
                    track_ids_list = results[0].boxes.id.cpu().numpy().astype(int)
                    class_ids_from_model = results[0].boxes.cls.cpu().numpy().astype(int)
                    confidences_list = results[0].boxes.conf.cpu().numpy()

                    for current_box, track_id, cls_id, conf_score in zip(boxes_coords, track_ids_list, class_ids_from_model, confidences_list):
                        if conf_score < confidence_thresh: continue

                        object_class_name = f"class_{cls_id}"
                        if is_world_model:
                            if 0 <= cls_id < len(class_name_source_map_or_list):
                                object_class_name = class_name_source_map_or_list[cls_id]
                            else:
                                logging.error(f"YOLO-World: Detected unexpected class ID {cls_id}")
                                continue
                        else:
                            object_class_name = class_name_source_map_or_list.get(cls_id, f"class_{cls_id}")

                        timestamp_str_display = format_timestamp(current_timestamp_seconds, for_filename=False)
                        tracked_object_info[track_id].append((frame_idx, tuple(current_box), conf_score, timestamp_str_display))

                        x1, y1, x2, y2 = current_box
                        box_area = (x2 - x1) * (y2 - y1)
                        if box_area > max_box_areas[track_id]:
                            max_box_areas[track_id] = box_area
                            representative_frames[track_id] = (frame.copy(), object_class_name, tuple(current_box), conf_score, timestamp_str_display)
                # --- End of processing logic ---

            # Update progress bar based on total frames read
            progress_percent = int((frame_idx + 1) / total_frames * 100) if total_frames > 0 else 0
            processing_fps = (frame_idx + 1) / (time.time() - start_time + 1e-6)
            pb_instance.progress(progress_percent, text=f"Scanning video‚Ä¶ {progress_percent}% (Scan FPS: {processing_fps:.2f})")
            
            frame_idx += 1 # Always advance to the next frame

        if cap: cap.release()
        pb_instance.progress(100, text="Video processing complete!")
        time.sleep(0.5)
        progress_bar_element.empty()
        logging.info("Video processing finished successfully.")
        return tracked_object_info, representative_frames

    except Exception as e:
        st.error(f"An error occurred during video processing: {e}")
        logging.exception(f"An unexpected error occurred in process_video_unified: {e}")
        if hasattr(progress_bar_element, "empty"): progress_bar_element.empty()
        return {}, {}

# -----------------------------------------------------------------------------
#  Helper ‚Äî Persist Annotated Results (for Download)
# -----------------------------------------------------------------------------
def persist_annotated_results(output_target_dir, representative_frames_data,
                              tracked_data_info, original_video_path):
    """Saves annotated representative frames and all tracked frames to a specified directory."""
    if not representative_frames_data and not tracked_data_info:
        logging.info("No results to save to disk.")
        return False

    try:
        if os.path.exists(output_target_dir):
            logging.info(f"Output directory {output_target_dir} exists, removing...")
            shutil.rmtree(output_target_dir, ignore_errors=True)

        os.makedirs(output_target_dir, exist_ok=True)
        logging.info(f"Saving annotated results to: {output_target_dir}")

        # --- Save Representative Frames ---
        rep_frames_dir = os.path.join(output_target_dir, "representative_frames")
        os.makedirs(rep_frames_dir, exist_ok=True)
        if representative_frames_data:
            for track_id, (frame_bgr, class_name, box, conf, timestamp_str) in representative_frames_data.items():
                annotated_frame = draw_bounding_box_unified(frame_bgr, box, track_id, class_name, conf)
                safe_class_name = "".join(c if c.isalnum() else "_" for c in class_name)
                timestamp_for_file = format_timestamp(None)
                if timestamp_str and ":" in timestamp_str:
                     try:
                        parts = list(map(int, timestamp_str.split(':')))
                        seconds_from_str = parts[0]*3600 + parts[1]*60 + parts[2]
                        timestamp_for_file = format_timestamp(seconds_from_str, for_filename=True)
                     except (ValueError, IndexError): logging.warning(f"Malformed timestamp for rep frame: {timestamp_str}")
                output_filename = f"rep_track_{track_id:03d}_{safe_class_name}_time_{timestamp_for_file}_conf_{conf:.2f}.jpg"
                output_filepath = os.path.join(rep_frames_dir, output_filename)
                cv2.imwrite(output_filepath, annotated_frame)
        logging.info("Saved annotated representative frames.")

        # --- Save Detailed Tracked Frames (On-Demand) ---
        tracked_details_dir = os.path.join(output_target_dir, "tracked_object_details")
        os.makedirs(tracked_details_dir, exist_ok=True)
        if tracked_data_info:
            all_required_indices = set()
            for frame_entries in tracked_data_info.values():
                for entry in frame_entries:
                    all_required_indices.add(entry[0]) # entry[0] is frame_idx

            logging.info(f"Extracting {len(all_required_indices)} unique frames for download.")
            all_extracted_frames = extract_frames_by_indices(original_video_path, all_required_indices)
            logging.info("Frame extraction for download complete.")

            for track_id, frame_entries in tracked_data_info.items():
                class_name_for_folder = "unknown_class"
                if track_id in representative_frames_data:
                    class_name_for_folder = representative_frames_data[track_id][1]
                safe_class_name_for_folder = "".join(c if c.isalnum() else "_" for c in class_name_for_folder)
                track_specific_dir = os.path.join(tracked_details_dir, f"track_{track_id:03d}_{safe_class_name_for_folder}")
                os.makedirs(track_specific_dir, exist_ok=True)

                for idx, (frame_idx_detail, box, conf, timestamp_str) in enumerate(frame_entries):
                    original_frame_bgr = all_extracted_frames.get(frame_idx_detail)
                    if original_frame_bgr is not None:
                        annotated_frame_for_detail = draw_bounding_box_unified(original_frame_bgr, box, track_id, class_name_for_folder, conf)
                        timestamp_for_file_detail = format_timestamp(None)
                        if timestamp_str and ":" in timestamp_str:
                             try:
                                parts_detail = list(map(int, timestamp_str.split(':')))
                                seconds_from_str_detail = parts_detail[0]*3600 + parts_detail[1]*60 + parts_detail[2]
                                timestamp_for_file_detail = format_timestamp(seconds_from_str_detail, for_filename=True)
                             except (ValueError, IndexError): logging.warning(f"Malformed timestamp for detail frame: {timestamp_str}")
                        detail_frame_filename = f"frame_{idx:05d}_time_{timestamp_for_file_detail}_conf_{conf:.2f}.jpg"
                        detail_frame_save_path = os.path.join(track_specific_dir, detail_frame_filename)
                        cv2.imwrite(detail_frame_save_path, annotated_frame_for_detail)
        logging.info("Saved annotated detailed tracking frames.")
        return True
    except Exception as e:
        logging.exception(f"Error saving annotated results to {output_target_dir}: {e}")
        return False


# -----------------------------------------------------------------------------
#  Helper ‚Äî Trigger ZIP Preparation
# -----------------------------------------------------------------------------
def trigger_zip_preparation():
    """Handles the logic of saving results and zipping them, storing bytes in session_state."""
    ss = st.session_state
    ss.prepared_zip_bytes = None # Reset first

    if not (ss.video_processed and ss.representative_frames and ss.uploaded_file_name and ss.video_path):
        logging.warning("trigger_zip_preparation call missing required session state data.")
        st.toast("Cannot prepare download: Missing processed data.", icon="‚ö†Ô∏è")
        return

    video_name_without_ext = os.path.splitext(ss.uploaded_file_name)[0]
    safe_video_name = "".join(c if c.isalnum() else "_" for c in video_name_without_ext)
    final_results_output_dir = os.path.join(BASE_OUTPUT_DIR, f"{safe_video_name}_results_hierarchical")

    save_success = persist_annotated_results(
        final_results_output_dir,
        ss.representative_frames,
        ss.tracked_data,
        ss.video_path
    )

    if not save_success:
        logging.error("Failed to persist detailed results in persist_annotated_results.")
        st.toast("Error: Failed to save results before zipping.", icon="üö®")
        return

    ss.user_output_dir_path = os.path.abspath(final_results_output_dir)
    logging.info(f"Annotated results saved to (for zipping): {ss.user_output_dir_path}")

    archive_temp_basename = os.path.join(tempfile.gettempdir(), f"{safe_video_name}_results_archive")
    
    generated_zip_full_path = None
    try:
        generated_zip_full_path = shutil.make_archive(
            base_name=archive_temp_basename,
            format='zip',
            root_dir=os.path.dirname(final_results_output_dir),
            base_dir=os.path.basename(final_results_output_dir)
        )
    except Exception as e_zip:
        logging.exception(f"Error creating ZIP file: {e_zip}")
        st.toast(f"Error: Failed to create archive: {e_zip}", icon="üö®")
        return

    if generated_zip_full_path and os.path.exists(generated_zip_full_path):
        with open(generated_zip_full_path, "rb") as f:
            ss.prepared_zip_bytes = f.read()
        st.toast("Files are ready for download!", icon="‚úÖ")
        # Clean up the temp zip file on disk after reading into memory
        try:
            os.remove(generated_zip_full_path)
        except Exception as e:
            logging.warning(f"Could not clean up temp zip file {generated_zip_full_path}: {e}")
    else:
        logging.error("Could not read the newly generated ZIP file.")
        st.toast("Error: Could not read the archive file.", icon="üö®")

# -----------------------------------------------------------------------------
#  Streamlit Interface Setup
# -----------------------------------------------------------------------------
st.set_page_config(page_title="YOLO Áâ©‰ª∂ËøΩËπ§ App", layout="wide")

ss = st.session_state
_default_session_values = {
    "selected_model_type": MODEL_TYPES[0],
    "active_model_config": STANDARD_MODEL_CONFIG,
    "loaded_model_object": None,
    "tracked_data": None,
    "representative_frames": None,
    "selected_track_id": None,
    "video_processed": False,
    "uploaded_file_name": None,
    "video_path": None,
    "current_prompt_world": WORLD_MODEL_CONFIG["default_prompt"],
    "last_processed_settings": "",
    "view_mode": "all_objects",
    "confidence_threshold": STANDARD_MODEL_CONFIG["confidence_threshold"],
    "user_output_dir_path": None,
    "prepared_zip_bytes": None, # New state for two-step download
    "all_objects_current_page": 1,
    "all_objects_items_per_page": 48,
}
for key, value in _default_session_values.items():
    if key not in ss:
        ss[key] = value

main_area_progress_bar_placeholder = st.empty()

def reset_app_state():
    """Resets state when model or video changes."""
    ss.tracked_data = None
    ss.representative_frames = None
    ss.selected_track_id = None
    ss.video_processed = False
    ss.last_processed_settings = ""
    ss.view_mode = 'all_objects'
    ss.user_output_dir_path = None
    ss.all_objects_current_page = 1
    ss.prepared_zip_bytes = None # Reset prepared download

with st.sidebar:
    st.header("‚öôÔ∏è ÊéßÂà∂Èù¢Êùø")

    previous_selected_model_type = ss.selected_model_type
    ss.selected_model_type = st.radio(
        "ÈÅ∏ÊìáÊ®°ÂûãÈ°ûÂûã:",
        MODEL_TYPES,
        key="model_type_radio_selector",
        horizontal=True
    )
    is_currently_world_model = (ss.selected_model_type == "YOLO-World")

    if previous_selected_model_type != ss.selected_model_type:
        ss.active_model_config = WORLD_MODEL_CONFIG if is_currently_world_model else STANDARD_MODEL_CONFIG
        ss.loaded_model_object = None
        ss.confidence_threshold = ss.active_model_config["confidence_threshold"]
        if is_currently_world_model:
            ss.current_prompt_world = WORLD_MODEL_CONFIG["default_prompt"]
        reset_app_state()
        st.rerun()

    st.caption(f"‰ΩøÁî®Ê®°Âûã: {ss.active_model_config.get('display_name', ss.active_model_config['model_path'])}")

    if is_currently_world_model:
        ss.current_prompt_world = st.text_area(
            "Ëº∏ÂÖ•Ë¶ÅÂÅµÊ∏¨ÁöÑÁâ©‰ª∂ (‰ª•ÈÄóËôüÂàÜÈöî):",
            value=ss.current_prompt_world,
            height=100,
            key="world_model_prompt_input"
        )
    else:
        fixed_classes_display = ", ".join(STANDARD_MODEL_CONFIG['target_classes_names'].values())
        st.info(f"Âõ∫ÂÆöÂÅµÊ∏¨ÁõÆÊ®ô: {fixed_classes_display}")

    ss.confidence_threshold = st.slider(
        "‰ø°Ë≥¥Â∫¶ÈñæÂÄº:",
        0.05, 0.95,
        ss.confidence_threshold,
        0.05,
        key="confidence_level_slider"
    )

    uploaded_video_file = st.file_uploader(
        "ÈÅ∏ÊìáÂΩ±ÁâáÊ™îÊ°à",
        ["mp4", "avi", "mov", "mkv"],
        key="video_file_uploader_widget"
    )
    if uploaded_video_file is not None and ss.uploaded_file_name != uploaded_video_file.name:
        reset_app_state()
        ss.uploaded_file_name = uploaded_video_file.name

        if ss.video_path and os.path.exists(ss.video_path):
            try:
                os.remove(ss.video_path)
            except OSError as e:
                logging.warning(f"Could not remove old temp video file: {ss.video_path}, error: {e}")

        try:
            with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_video_file.name)[1]) as tmp_vid_file:
                tmp_vid_file.write(uploaded_video_file.getvalue())
                ss.video_path = tmp_vid_file.name
            logging.info(f"New temp video file created: {ss.video_path}")
            st.rerun()
        except Exception as e:
            st.error(f"Failed to create temporary video file: {e}")
            logging.exception(f"Error creating temp video file: {e}")
            ss.video_path = None

    if ss.video_path:
        if ss.loaded_model_object is None:
            model_path_for_loading = ss.active_model_config['model_path']
            with st.spinner(f"Ê≠£Âú®ËºâÂÖ•Ê®°Âûã ({model_path_for_loading})..."):
                ss.loaded_model_object = load_model_unified(model_path_for_loading)
                if ss.loaded_model_object is None:
                    st.error(f"Ê®°Âûã {model_path_for_loading} ËºâÂÖ•Â§±ÊïóÔºåÁÑ°Ê≥ïËôïÁêÜÂΩ±Áâá„ÄÇ")
                else:
                    st.success(f"Ê®°Âûã {model_path_for_loading} ËºâÂÖ•ÊàêÂäüÔºÅ")
                    st.rerun()

        if ss.loaded_model_object:
            current_processing_config_summary = (
                f"Model: {ss.selected_model_type} | "
                f"Prompt: {ss.current_prompt_world if is_currently_world_model else 'Standard Predefined'} | "
                f"Confidence: {ss.confidence_threshold:.2f}"
            )

            button_label = "üöÄ ÈñãÂßãËôïÁêÜÂΩ±Áâá"
            if ss.video_processed and ss.last_processed_settings != current_processing_config_summary:
                button_label = "üîÑ ‰ΩøÁî®Êñ∞Ë®≠ÂÆöÈáçÊñ∞ËôïÁêÜ"
            elif ss.video_processed:
                button_label = "‚úÖ ËôïÁêÜÂÆåÊàê"

            if st.button(button_label, use_container_width=True, type="primary", key="process_button_key", disabled=ss.video_processed and ss.last_processed_settings == current_processing_config_summary):
                yolo_world_custom_classes_list = []
                if is_currently_world_model:
                    yolo_world_custom_classes_list = [c.strip() for c in ss.current_prompt_world.split(',') if c.strip()]
                    if not yolo_world_custom_classes_list:
                        st.warning("YOLO-World ÈúÄË¶ÅËá≥Â∞ë‰∏ÄÂÄãÊúâÊïàÊèêÁ§∫Ë©ûÔºÅ")
                        st.stop()

                reset_app_state()

                with st.spinner(f"{ss.selected_model_type} ÂΩ±ÁâáËôïÁêÜ‰∏≠‚Ä¶"):
                    tracked_data_result, representative_frames_result = process_video_unified(
                        ss.video_path,
                        ss.loaded_model_object,
                        is_currently_world_model,
                        ss.active_model_config,
                        yolo_world_custom_classes_list,
                        ss.confidence_threshold,
                        main_area_progress_bar_placeholder
                    )
                    ss.tracked_data = tracked_data_result
                    ss.representative_frames = representative_frames_result
                    ss.video_processed = True
                    ss.last_processed_settings = current_processing_config_summary

                st.success("ÂΩ±ÁâáËôïÁêÜÂÆåÊàêÔºÅÁµêÊûúÂ∑≤ÂèØ‰æõÊ™¢Ë¶ñ„ÄÇ")
                st.rerun()

    if ss.video_processed:
        st.markdown("---")
        st.subheader("üëÅÔ∏è Ê™¢Ë¶ñÈÅ∏È†Ö")

        current_view_mode = ss.view_mode
        if st.button("ÊâÄÊúâËøΩËπ§Áâ©‰ª∂",
                      type="primary" if ss.view_mode == 'all_objects' else "secondary",
                      use_container_width=True, key="view_all_objects_btn_key"):
            if current_view_mode != 'all_objects':
                ss.all_objects_current_page = 1
            ss.view_mode = 'all_objects'
            ss.selected_track_id = None
            st.rerun()

        if ss.representative_frames:
            sorted_track_ids = sorted(ss.representative_frames.keys())
            if st.button("ÁâπÂÆöÁâ©‰ª∂ÊâÄÊúâÁï´Èù¢",
                          type="primary" if ss.view_mode == 'single_object' else "secondary",
                          use_container_width=True, key="view_specific_object_btn_key"):
                ss.view_mode = 'single_object'
                ss.selected_track_id = sorted_track_ids[0] if sorted_track_ids else None
                st.rerun()

            if ss.view_mode == 'single_object' and sorted_track_ids:
                selected_id_choice = st.selectbox(
                    "ÈÅ∏ÊìáÁâ©‰ª∂ ID:",
                    sorted_track_ids,
                    index=sorted_track_ids.index(ss.selected_track_id) if ss.selected_track_id in sorted_track_ids else 0,
                    format_func=lambda tid_key: f"ID:{tid_key} ({ss.representative_frames[tid_key][1]})",
                    key="select_specific_object_id_selectbox"
                )
                if selected_id_choice != ss.selected_track_id:
                    ss.selected_track_id = selected_id_choice
                    st.rerun()

        st.markdown("---")
        st.subheader("üì• ‰∏ãËºâÁµêÊûú")
        if ss.representative_frames and ss.uploaded_file_name:
            if st.button("Ê∫ñÂÇô‰∏ãËºâ", use_container_width=True, key="prepare_download_button"):
                with st.spinner("Ê≠£Âú®Ê∫ñÂÇô‰∏¶Â£ìÁ∏ÆÁµêÊûúÊ™îÊ°àÔºåË´ãÁ®çÂÄô..."):
                    trigger_zip_preparation()
                st.rerun()

            _video_name_no_ext_dl = os.path.splitext(ss.uploaded_file_name)[0]
            _safe_video_name_dl = "".join(c if c.isalnum() else "_" for c in _video_name_no_ext_dl)
            _download_zip_filename = f"{_safe_video_name_dl}_results.zip"

            st.download_button(
                label="‰∏ãËºâÊ®ôË®ªÁµêÊûú (ZIP)",
                data=ss.prepared_zip_bytes if ss.prepared_zip_bytes else b"",
                file_name=_download_zip_filename,
                mime="application/zip",
                key="download_annotated_results_zip_button",
                use_container_width=True,
                help="Ë´ãÂÖàÈªûÊìä‰∏äÊñπÁöÑ„ÄåÊ∫ñÂÇô‰∏ãËºâ„ÄçÔºåÊåâÈàïÂïüÁî®ÂæåÂç≥ÂèØ‰∏ãËºâ„ÄÇ",
                disabled=not ss.prepared_zip_bytes
            )
            if ss.user_output_dir_path and os.path.exists(ss.user_output_dir_path):
                st.caption(f"ÊèêÁ§∫ÔºöÊú™Â£ìÁ∏ÆÁöÑÁµêÊûúÂÑ≤Â≠òÊñº {ss.user_output_dir_path}")


# -----------------------------------------------------------------------------
#  Main Area Content (Video Preview / Results Display)
# -----------------------------------------------------------------------------
st.title("üé¨ YOLO ÈÄöÁî®Áâ©‰ª∂ÂÅµÊ∏¨ËàáËøΩËπ§")

if not ss.video_path:
    st.info("üëã Ê≠°ËøéÔºÅË´ãÂú®Â∑¶ÂÅ¥ÊéßÂà∂Èù¢ÊùøÈÅ∏ÊìáÊ®°ÂûãÈ°ûÂûã„ÄÅË®≠ÂÆöÂÅµÊ∏¨ÁõÆÊ®ô‰∏¶‰∏äÂÇ≥ÂΩ±ÁâáÊ™îÊ°à„ÄÇ")
    st.markdown(f"""
        - **Standard YOLO**: ÂÅµÊ∏¨È†êÂÆöÁæ©Áâ©‰ª∂ (‰æãÂ¶Ç: {", ".join(STANDARD_MODEL_CONFIG['target_classes_names'].values())})„ÄÇ
        - **YOLO-World**: Ëº∏ÂÖ•ÊÇ®ÊÉ≥ÂÅµÊ∏¨ÁöÑ‰ªªÊÑèÁâ©‰ª∂ÂêçÁ®± (‰æãÂ¶Ç: `a red apple, a blue car`)„ÄÇ
    """)
elif not ss.loaded_model_object:
     st.warning("Ê®°ÂûãÊ≠£Âú®ËºâÂÖ•ÊàñËºâÂÖ•Â§±Êïó„ÄÇË´ãÊ™¢Êü• Sidebar„ÄÇ")
else:
    video_col, empty_col = st.columns([2, 1])
    with video_col:
        st.subheader("üéûÔ∏è ÂΩ±ÁâáÈ†êË¶Ω")
        st.video(ss.video_path)

    if not ss.video_processed:
        st.info("ÂΩ±ÁâáÂ∑≤‰∏äÂÇ≥„ÄÇË´ãÈªûÊìäÂ∑¶ÂÅ¥ Sidebar ÁöÑ„ÄåüöÄ ÈñãÂßãËôïÁêÜÂΩ±Áâá„ÄçÊåâÈàï„ÄÇ")


if ss.video_processed:
    processed_model_type_disp, processed_prompt_text_disp, processed_conf_text_disp = "N/A", "N/A", "N/A"
    if ss.last_processed_settings:
        parts = {p.split(': ', 1)[0].lower(): p.split(': ', 1)[1] for p in ss.last_processed_settings.split(' | ')}
        processed_model_type_disp = parts.get('model', 'N/A')
        processed_prompt_text_disp = parts.get('prompt', 'N/A')
        processed_conf_text_disp = parts.get('confidence', 'N/A')

    if not ss.representative_frames:
        st.info(f"ËôïÁêÜÂÆåÊàê„ÄÇÊ®°Âûã {processed_model_type_disp} Âú® '{processed_prompt_text_disp}' ÁöÑÊ¢ù‰ª∂‰∏ãÔºà‰ø°Ë≥¥Â∫¶ ‚â• {processed_conf_text_disp}ÔºâÊú™ÂÅµÊ∏¨Âà∞‰ªª‰ΩïÁâ©‰ª∂„ÄÇ")
    else:
        if ss.view_mode == 'all_objects':
            st.header("üìä ÊâÄÊúâËøΩËπ§Áâ©‰ª∂ (‰ª£Ë°®Áï´Èù¢)")
            st.write(f"Ê®°Âûã: {processed_model_type_disp} | ÁõÆÊ®ô: '{processed_prompt_text_disp}' | ÊúÄ‰Ωé‰ø°Ë≥¥Â∫¶: {processed_conf_text_disp}")
            st.write(f"Á∏ΩÂÖ±ÂÅµÊ∏¨‰∏¶ËøΩËπ§Âà∞ {len(ss.representative_frames)} ÂÄãÁç®Á´ãÁâ©‰ª∂„ÄÇ")

            # --- Pagination Controls ---
            total_items = len(ss.representative_frames)
            items_per_page = st.select_slider("ÊØèÈ†ÅÈ°ØÁ§∫Áâ©‰ª∂Êï∏:", options=[12, 24, 48, 96], value=ss.all_objects_items_per_page)
            if items_per_page != ss.all_objects_items_per_page:
                ss.all_objects_items_per_page = items_per_page
                ss.all_objects_current_page = 1
                st.rerun()

            total_pages = max(1, math.ceil(total_items / ss.all_objects_items_per_page))
            ss.all_objects_current_page = max(1, min(ss.all_objects_current_page, total_pages))
            start_index = (ss.all_objects_current_page - 1) * ss.all_objects_items_per_page
            end_index = start_index + ss.all_objects_items_per_page
            sorted_rep_ids = sorted(list(ss.representative_frames.keys()))
            current_page_track_ids = sorted_rep_ids[start_index:end_index]

            num_cols = st.slider("ÊØèË°åÈ°ØÁ§∫Áâ©‰ª∂Êï∏ (Á∂≤Ê†ºË¶ñÂúñ):", 2, 8, 4)
            grid_cols = st.columns(num_cols)

            for i, track_id_val in enumerate(current_page_track_ids):
                with grid_cols[i % num_cols]:
                    frame_bgr, c_name, box, conf, ts = ss.representative_frames[track_id_val]
                    img_with_box = draw_bounding_box_unified(frame_bgr, box, track_id_val, c_name, conf)
                    st.image(cv2.cvtColor(img_with_box, cv2.COLOR_BGR2RGB), caption=f"ID: {track_id_val} ({c_name}, {conf:.2f}) at {ts}", use_container_width=True)
                    if st.button(f"Ê™¢Ë¶ñ ID {track_id_val} ÊâÄÊúâÁï´Èù¢", key=f"view_all_btn_{track_id_val}", use_container_width=True):
                        ss.selected_track_id = track_id_val
                        ss.view_mode = 'single_object'
                        st.rerun()

            # --- Pagination Navigation ---
            if total_pages > 1:
                st.markdown("---")
                nav_cols = st.columns([1, 2, 1])
                if nav_cols[0].button("‚¨ÖÔ∏è ‰∏ä‰∏ÄÈ†Å", disabled=(ss.all_objects_current_page <= 1)):
                    ss.all_objects_current_page -= 1
                    st.rerun()
                nav_cols[1].markdown(f"<p style='text-align: center; margin-top: 0.5em;'>Á¨¨ {ss.all_objects_current_page} / {total_pages} È†Å</p>", unsafe_allow_html=True)
                if nav_cols[2].button("‰∏ã‰∏ÄÈ†Å ‚û°Ô∏è", disabled=(ss.all_objects_current_page >= total_pages)):
                    ss.all_objects_current_page += 1
                    st.rerun()

        elif ss.view_mode == 'single_object' and ss.selected_track_id is not None:
            current_id = ss.selected_track_id
            if current_id in ss.tracked_data and current_id in ss.representative_frames:
                frames_info = ss.tracked_data[current_id]
                _, c_name_header, _, conf_header, ts_header = ss.representative_frames[current_id]

                st.header(f"üñºÔ∏è Áâ©‰ª∂ ID: {current_id} ({c_name_header}) ÁöÑÊâÄÊúâÁï´Èù¢")
                st.write(f"Ê≠§Áâ©‰ª∂Âá∫ÁèæÁöÑÁ∏ΩÂπÄÊï∏: {len(frames_info)}„ÄÇ")

                # On-demand frame extraction for display
                frame_indices_to_show = [info[0] for info in frames_info]
                with st.spinner(f"Ê≠£Âú®Êì∑Âèñ {len(frame_indices_to_show)} ÂÄãÁï´Èù¢‰ª•‰æõÊ™¢Ë¶ñ..."):
                    extracted_frames_for_viewing = extract_frames_by_indices(ss.video_path, frame_indices_to_show)

                cols_per_row = st.number_input("ÊØèË°åÈ°ØÁ§∫ÂπÄÊï∏:", min_value=2, max_value=10, value=4)
                detailed_cols = st.columns(cols_per_row)

                for idx, (frame_idx_detail, box_detail, conf_detail, ts_detail) in enumerate(frames_info):
                    with detailed_cols[idx % cols_per_row]:
                        frame_bgr_detail = extracted_frames_for_viewing.get(frame_idx_detail)
                        if frame_bgr_detail is not None:
                            annotated_detail = draw_bounding_box_unified(frame_bgr_detail, box_detail, current_id, c_name_header, conf_detail)
                            st.image(cv2.cvtColor(annotated_detail, cv2.COLOR_BGR2RGB), caption=f"ÂπÄ {idx+1} ({ts_detail}) ‰ø°Ë≥¥Â∫¶: {conf_detail:.2f}", use_container_width=True)
                        else:
                            st.warning(f"ÁÑ°Ê≥ïËºâÂÖ•ÂπÄÁ¥¢Âºï {frame_idx_detail}„ÄÇ")
            else:
                st.warning(f"Êâæ‰∏çÂà∞ËªåË∑° ID {ss.selected_track_id} ÁöÑË≥áÊñô„ÄÇË´ãÂæûÂ∑¶ÂÅ¥ÈÅ∏ÂñÆÈÅ∏ÊìáÊúâÊïàÁöÑÁâ©‰ª∂ ID ÊàñËøîÂõûÁ∏ΩË¶Ω„ÄÇ")
                ss.view_mode = 'all_objects'
                ss.selected_track_id = None
                st.rerun()

# -----------------------------------------------------------------------------
#  Footer
# -----------------------------------------------------------------------------
st.markdown("---")
st.caption("Áî± Ultralytics YOLO Âíå Streamlit È©ÖÂãï")
